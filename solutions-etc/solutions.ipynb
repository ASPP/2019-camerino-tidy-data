{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy hints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Jupyter shortcut keys:\n",
    "\n",
    "- Esc : get into Command mode (leaves Edit mode)\n",
    "- Enter : edit a cell (puts you in Edit mode)\n",
    "- h : see help (see all commands)\n",
    "- Shift+Enter or Ctrl+Enter : run the code in the cell\n",
    "- a / b : add new cell above/below\n",
    "- m : turn current cell into a Markdown cell\n",
    "- y : turn current cell into a Code cell\n",
    "- 1-6 : turn current cell into a heading (a type of Markdown cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get help on Python objects and functions with `help()` or the `?` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:29:49.600774Z",
     "start_time": "2019-01-19T11:29:49.581459Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:29:50.000633Z",
     "start_time": "2019-01-19T11:29:49.987260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This causes Jupyter to display any matplotlib plots directly in the notebook\n",
    "# It also works for pandas and seaborn, since they use matplotlib to render plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:29:51.169379Z",
     "start_time": "2019-01-19T11:29:51.163406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pyplot (as plt) is the module we'll primarily use to instantiate matplotlib plot objects\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the Pandas website and documentation at https://pandas.pydata.org/\n",
    "\n",
    "Pandas is a popular Python library for handling tabular data. It provides much of the same functionality for Python as do data frames in the R language. \n",
    "\n",
    "The fundamental data types in Pandas are a Series, representing a 1D array of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"Diego\",\"Jessica\",\"Farah\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a DataFrame, representing a 2D table of data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name': [\"Diego\",\"Jessica\",\"Farah\"],\n",
    "                   'Age': [34, 27, 50]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a DataFrame like a spreadsheet or a table in a database; every column represents a variable in the dataset. Each column of a DataFrame has a particular type (ints, floats, datetimes, strings etc) and each column can be treated as a Pandas Series.\n",
    "\n",
    "Above, we constructed data manually using lists and dicts. For the rest of this workshop, we will work with real data. DataFrames are the natural type to use when reading in tabular data from, for instance, CSV files or Excel files.\n",
    "\n",
    "Here's example to read in some small datasets which we can use for demo purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "cars = pd.read_csv('mtcars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we'll use for this workshop is from the [Long Term Evolution Experiment (LTEE)](http://myxo.css.msu.edu/ecoli/). This experiment has been running for over 30 years and over 50,000 E. coli generations, and is still ongoing. Twelve separate populations of E. coli have been propagated for the life of the experiment. Every 500 generations, each population is cloned and stored, allowing researchers to study evolutionary behaviour over the long term, and to \"rewind and replay\" alternate evolutionary trajectories by propagating from an earlier clone. \n",
    "\n",
    "Several interesting events have occurred during the experiment. Some populations have spontaneously developed hypermutator phenotypes. In addition, around generation 31,000 one population, Ara-3, spontaneously developed a rare and novel Cit+ mutation, giving it the ability to metabolise citrate in the substrate.\n",
    "\n",
    "There have been many publications from this experiment. A handful:\n",
    "\n",
    "- [Blount et al 2008: Historical contingency and the evolution of a key innovation in an experimental population of Escherichia coli](https://www.pnas.org/content/105/23/7899) - on the spontaneous development of citrate metabolisation and on potentiating mutations\n",
    "- [Tenaillon et al 2016: Tempo and mode of genome evolution in a 50,000-generation experiment](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4988878) - various investigations by sequencing and variant-calling over 50,000 generations of clones, including discussion of hypermutator phenotypes and genetic drift vs natural selection.\n",
    "\n",
    "Sequence data from clones is available, but for this workshop we'll just be using some published tabular data.\n",
    "\n",
    "A version of this dataset is also used by the [Data Carpentry lessons on Genomics](https://datacarpentry.org/genomics-workshop/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the repository you'll find the files:\n",
    "\n",
    "- ltee_sampleruns.csv : sample and sequencing run metadata for the E. coli clones\n",
    "- ltee_mutations.csv : analysis output from variant calling on the E. coli clones\n",
    "- ltee_relative_fitness.tsv : relative fitness values for each population and generation up to generation 10,000\n",
    "- ltee_cell_size.tsv : cell sizes for each population and generation up to 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the sample and run metadata. Pandas has functions for reading in many data types. Try looking at the documentation for `read_csv()` by running `help(pd.read_csv)` or `pd.read_csv?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns = pd.read_csv('ltee_sampleruns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of rows and columns\n",
    "sampleruns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The first few rows\n",
    "sampleruns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column data types\n",
    "sampleruns.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "sampleruns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index (i.e. row names)\n",
    "# In this case we didn't provide an index and rows have simply been numbered for us by Pandas\n",
    "sampleruns.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "1. Use `pd.read_csv()` to read the file `ltee_mutations.csv` into a variable called `mutations`.\n",
    "2. Check the column headings and the number of rows in this dataset, and have a look at the first few rows. Compare the size of the dataset and the variables to `sampleruns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = pd.read_csv('ltee_mutations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and slicing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract a column from the DataFrame by indexing with square brackets, e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a column\n",
    "sampleruns['Strain ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's set our index (row names) to something more meaningful to make it easier to see what's going on. The Strain ID uniquely identifies each sample, so it is probably a sensible index. We can use `sampleruns.set_index()`, or we can assign to the index directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns.index = sampleruns['Strain ID']\n",
    "sampleruns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important ways to extract data from a DataFrame are `loc` and `iloc`. `loc` uses the index and the column names; `iloc` uses the row and column numbers, counting from zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns.loc['REL768B', 'Accession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row 0, column 9\n",
    "sampleruns.iloc[0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 1-3, column 9\n",
    "sampleruns.iloc[1:4, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All columns\n",
    "sampleruns.loc['REL768B', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists let us specify any set of rows and columns, in any order\n",
    "sampleruns.loc[['REL768A','REL958A'], ['Read Type', 'Read Length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use True/False values to perform boolean indexing. \n",
    "# Pandas will return the rows/columns matching the True values we pass in.\n",
    "# This will be useful later for filtering data\n",
    "iris.loc[0:5, [True, False, True, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "1. Set the index of `mutations` to be the same as the \"Strain ID\" column.\n",
    "2. Extract the population, generation, and number of total mutations for strain REL11345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations.index = mutations['Strain ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations.loc['REL11345', ['Population','Generation', 'Total Mutations']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column of a DataFrame is a Series object. Series have a data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Sequencing Depth'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a DataFrame, a Series has an index. In this case we got our Series from a column of a DataFrame, so it will have the same index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Sequencing Depth'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several convenience functions defined on Series. For instance, we can find the average sequencing depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Sequencing Depth'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for numeric variables we have, for instance, `.min()` and `.max()`, `.median()`, `std()`, and `sum()`.\n",
    "\n",
    "`.describe()` is a convenience function for getting several summary statistics at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Sequencing Depth'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-numeric variable types such as strings and categoricals, we may want to look at the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Read Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns['Read Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas makes use of numpy vectorisation, meaning we can do operations on Series with simple syntax, and it will be efficient to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 500 generations takes 75 days\n",
    "mutations['Days'] = mutations['Generation'] * 0.15\n",
    "mutations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mutations['Total Deleted Base Pairs'] + mutations['Total Inserted Base Pairs']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that the `Analysis Notes` column contains a lot of NaN's. This means \"not a number\" and represents a missing value - i.e. these cells are empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which values are missing with `.isnull()`. This converts every value in the DataFrame (or Series) into a boolean True/False value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampleruns.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding up booleans will treat `True` as `1` and `False` as `0`. A common approach is to use `sum()` to count how many `True` values there are. So we can count missing values like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sampleruns` had 264 rows, so it looks like there are a few non-empty note cells. We could count this explicitly by taking the logical `not` of our True/False values, i.e. adding up cells where `isnull()` is `False`. For manipulating array-like data, we can't use the `not`, `and` and `or` boolean operators. Instead we need to use the bitwise operators `~`, `&`, and `|`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~sampleruns.isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Pandas summed each column. We can use `sum(axis=1)` to override this default and sum each row instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort on a field, or list of fields, with `.sort_values()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a random example subset\n",
    "subset = sampleruns.sample(15)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset.sort_values('Generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subset.sort_values(['Population','Generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter datasets using boolean indexing. This means that if we use a logical expression produce a boolean Series with a logical expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['Population'] == 'Ara+5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can then select out only the rows (or sometimes columns) where that logical expression is True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset.loc[subset['Population'] == 'Ara+5', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "1. Filter the `sampleruns` dataset to extract only rows which contain Analysis Notes, i.e. those where this field is not empty.\n",
    "2. Filter the `mutations` dataset to extract only samples with more than 1500 total mutations. \n",
    "3. Sort the resulting data from (2) by the number of \"Small Indels\". Have a look at the resulting Population and Generation columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleruns[ ~sampleruns['Analysis Notes'].isnull() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations['Total Mutations'] > 1500].sort_values('Small Indels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: tidy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to \"untidy data\" discussion spreadsheet](https://docs.google.com/spreadsheets/d/1P94oEzgxNzlpvYiento53tZxJwaHYi8gpcdpDouu2jw/edit?usp=sharing)\n",
    "\n",
    "(Don't look too far into this spreadsheet before we get up to it, as it includes solutions which are a spoiler for the exercise.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reshape data using particular columns, with `melt` and `pivot` or `pivot_table`. We'll have a look at this below.\n",
    "\n",
    "We can also reshape data using the column names and index, with `stack` and `unstack`. This requires MultiIndexes, which we won't go into today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two tiny \"wide\" datasets based on our \"untidy\" housing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:51:16.434295Z",
     "start_time": "2019-01-19T11:51:16.254462Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales_wide1 = pd.read_csv('housing-data-wide1.csv')\n",
    "sales_wide1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:54:26.755381Z",
     "start_time": "2019-01-19T11:54:26.723723Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales_wide2 = pd.read_csv('housing-data-wide2.csv', parse_dates=['date1','date2'])\n",
    "sales_wide2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we reshape these into tidy form? \n",
    "\n",
    "The Pandas `melt` function will do this. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_wide1.melt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has put every variable (i.e. every column) into the new `variable` column. This probably isn't what we want. It's only the price columns that are \"wide\", the other variables were fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain columns property_id and bedrooms\n",
    "sales_wide1.melt(id_vars=['property_id','bedrooms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is getting close to what we want. The `variable` column contains the original column names and tells us whether the price we're looking at was from the first or second sale (this may or may not be information we care about). The `value` column contains values in the melted columns, i.e. the actual price. \n",
    "\n",
    "Now we technically have long form and have eliminated the duplicated `price` variable; all prices are now in the `value` column. Notice that properties can now appear more than once in the table; conceptually, we have a row per sale rather than a row per property. \n",
    "\n",
    "We can tell `melt()` what to call the `variable` and `value` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_tidy = sales_wide1.melt(id_vars=['property_id','bedrooms'], \n",
    "                 var_name='sale_number',\n",
    "                 value_name='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have empty extra rows where there was no sale in the original table, i.e. rows 3 and 5. We could use `dropna()` to get rid of these. A more generic approach would be to use filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales_wide1.melt(id_vars=['property_id','bedrooms'], \n",
    "                                     var_name='sale_number',\n",
    "                                     value_name='price')\n",
    "sales = sales[~sales['price'].isnull()]\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good! Now we could run commands like `sales[\"price\"].mean()` and get a sensible answer. We'll also be able to use the data easily to produce plots.\n",
    "\n",
    "If you want a challenge, think about how you could convert `sales_wide2` to tidy form - it's a fair bit harder.\n",
    "\n",
    "The inverse operation to `.melt()` is `.pivot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.pivot(index='property_id', columns='sale_number', values='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our two remaining LTEE datasets. \n",
    "\n",
    "These two files record measurements of:\n",
    "\n",
    "- the cell size for every population for the first 10,000 generations, measured every 1000 generations\n",
    "- the relative fitness for every population for the first 10,000 generations, as measured by the growth rate of the strain relative to a reference strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are TSV files, so specify tab as the delimiter\n",
    "cellsize = pd.read_csv('ltee_cell_size.tsv', sep=\"\\t\")\n",
    "fitness = pd.read_csv('ltee_relative_fitness.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make life easier down the track, we'll rename the columns to match the variable and population names used in the `sampleruns` and `mutations` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cellsize.columns = (['Generation'] + ['Ara-{}'.format(n) for n  in range(1,7)] + \n",
    "                    ['Ara+{}'.format(n) for n  in range(1,7)])\n",
    "cellsize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.columns = (['Generation'] + ['Ara-{}'.format(n) for n  in range(1,7)] + \n",
    "                    ['Ara+{}'.format(n) for n  in range(1,7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "The cell size and relative fitness data is in wide form. Convert each one to tidy form. When thinking about which columns are \"wide\", it may help to aim to match the variables in the `sampleruns` and `mutations` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellsize_tidy = cellsize.melt(id_vars='Generation', var_name='Population', value_name='Cell size')\n",
    "fitness_tidy = fitness.melt(id_vars='Generation', var_name='Population', value_name='Relative fitness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge two datasets together by matching corresponding variables.\n",
    "\n",
    "Our main options are `DataFrame.join()` and `pandas.merge()`. `merge()` is a little more flexible, so we'll demonstrate that.\n",
    "\n",
    "Recall the `cars` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `origin` column here, which is a number 1-3, is actually intended to represent the country of origin. It's encoded as:\n",
    "\n",
    "- USA : 1\n",
    "- Europe : 2\n",
    "- Japan : 3\n",
    "\n",
    "Let's make a DataFrame to represent this mapping. We'll add a fourth code for Australia, which doesn't appear in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_codes = pd.DataFrame(\n",
    "    {\n",
    "        'origin': [1,2,3],\n",
    "        'origin_country': ['USA','Europe','Japan']\n",
    "    }\n",
    ")\n",
    "origin_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pandas.merge()` to join our `cars` table to our `origin_codes` table using the shared `origin` field, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_withorigin = pd.merge(cars, origin_codes)\n",
    "cars_withorigin.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This \"just worked\" because Pandas correctly deduced that the identically-named field(s) were the ones to match on. Sometimes we might need to be more verbose. In this case, this accomplishes the same thing as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use origin from the left dataframe (cars) and from the right (origin_codes)\n",
    "# use how=\"left\" (keep all origin values that exist in the left dataframe)\n",
    "cars_withorigin = pd.merge(cars, origin_codes, left_on='origin', right_on='origin', how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to merge our `sampleinfo` and `mutations` columns. This time there are three shared fields: 'Strain ID', 'Population', and 'Generation'. In fact only 'Strain ID' is needed to uniquely identify  rows, but we want to specify all matching variables so that Pandas knows to only include each of these variables once in the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may need sampleruns.index.name = mutations.index.name = 'Index'\n",
    "ltee = pd.merge(sampleruns, mutations, on=['Strain ID','Population','Generation'])\n",
    "ltee.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the metadata on Mutator phenotypes is together with the information on actual mutations, we could try exploring the relationships between these fields. Here are a couple of previews of ways to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=ltee, x='Mutator', y='Total Mutations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee.groupby('Mutator')['Total Mutations'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Merge the cell size data on to the `ltee` table with `pd.merge()`, using the Generation and Population variables. This is only possible if it's been converted to tidy form first, with variable names and values corresponding to those in `1tee`! You will probably want to set `how=\"left\"` (if the cell size data is on the right), since the `ltee` table contains generations that don't exist in the cell size data, and we don't want to throw these rows away.\n",
    "\n",
    "Do the same with the relative fitness data.\n",
    "\n",
    "Have a look at missing and repeated values in the newly-added columns. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee_merged1 = pd.merge(ltee, cellsize_tidy, on=['Generation', 'Population'], how=\"left\")\n",
    "ltee_merged2 = pd.merge(ltee_merged1, fitness_tidy, on=['Generation', 'Population'], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish off, let's write out our tidied and merged table to a new file, for future analyses. To write to CSV, we can use the `to_csv` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use whatever you named your merged dataframe here!\n",
    "# Don't keep the index as we still have the Strain ID column\n",
    "ltee.to_csv('ltee_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy hints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Jupyter shortcut keys:\n",
    "\n",
    "- Esc : get into Command mode (leaves Edit mode)\n",
    "- Enter : edit a cell (puts you in Edit mode)\n",
    "- h : see help (see all commands)\n",
    "- Shift+Enter or Ctrl+Enter : run the code in the cell\n",
    "- a / b : add new cell above/below\n",
    "- m : turn current cell into a Markdown cell\n",
    "- y : turn current cell into a Code cell\n",
    "- 1-6 : turn current cell into a heading (a type of Markdown cell)\n",
    "\n",
    "You can get help on Python objects and functions with `help()` or the `?` operator.\n",
    "\n",
    "In general, we are using plotting libraries that return objects encapsulating the plot. You can check the type of these returned objects with `type()`. \n",
    "\n",
    "Some of the plotting libraries we use need to communicate a lot of data to the browser. Current versions of Jupyter shouldn't have a problem, but if you are running an older version, you may need to launch this notebook with a higher data rate limit: `jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:53.109645Z",
     "start_time": "2018-01-14T23:56:53.106000Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:53.128661Z",
     "start_time": "2018-01-14T23:56:53.118959Z"
    }
   },
   "outputs": [],
   "source": [
    "# This causes Jupyter to display any matplotlib plots directly in the notebook\n",
    "# It also works for seaborn, since seaborn uses matplotlib to render plots\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that Seaborn automatically changes Matplotlib's defaults *on import*. Not only your Seaborn plots, but also your Matplotlib plots, will look different once Seaborn is imported. If you don't want this behaviour, you can call `sns.reset_orig()` after import, or `import seaborn.apionly as sns` in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:53.136630Z",
     "start_time": "2018-01-14T23:56:53.132215Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop we're going to load in two main datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTEE data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the [Long Term Evolution Experiment (LTEE)](http://myxo.css.msu.edu/ecoli/). This experiment has been running for over 30 years and over 50,000 E. coli generations, and is still ongoing. Twelve separate populations of E. coli have been propagated for the life of the experiment. Every 500 generations, each population is cloned and stored, allowing researchers to study evolutionary behaviour over the long term, and to \"rewind and replay\" alternate evolutionary trajectories by propagating from an earlier clone. \n",
    "\n",
    "Several interesting events have occurred during the experiment. Some populations have spontaneously developed hypermutator phenotypes. In addition, around generation 31,000 one population, Ara-3, spontaneously developed a rare and novel Cit+ mutation, giving it the ability to metabolise citrate in the substrate.\n",
    "\n",
    "There have been many publications from this experiment. A handful:\n",
    "\n",
    "- [Blount et al 2008: Historical contingency and the evolution of a key innovation in an experimental population of Escherichia coli](https://www.pnas.org/content/105/23/7899) - on the spontaneous development of citrate metabolisation and on potentiating mutations\n",
    "- [Tenaillon et al 2016: Tempo and mode of genome evolution in a 50,000-generation experiment](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4988878) - various investigations by sequencing and variant-calling over 50,000 generations of clones, including discussion of hypermutator phenotypes and genetic drift vs natural selection.\n",
    "\n",
    "Sequence data from clones is available, but for this workshop we'll just be using some published tabular data.\n",
    "\n",
    "A version of this dataset is also used by the [Data Carpentry lessons on Genomics](https://datacarpentry.org/genomics-workshop/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we'll use a large flat file containing both sample metadata on each clone, and information on observed mutations in their genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have done the pandas and data tidying workshop and saved the final file,\n",
    "# you can try reading that file in here if you prefer\n",
    "ltee = pd.read_csv('ltee_merged.csv',\n",
    "                   index_col = 'Strain ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House sales data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data represents house sales in Seattle in 2014 and 2015. We have information on the houses themselves: location, size, quality, view, and whether the house is tagged as 'waterfront' or not. We also have information on the date and price of each sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:53.195524Z",
     "start_time": "2018-01-14T23:56:53.140978Z"
    }
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"housing-data-10000.csv\", \n",
    "                    usecols=['id','date','price','lat','long', 'zipcode',\n",
    "                             'waterfront','view','grade','sqft_living'],\n",
    "                    parse_dates=['date'], \n",
    "                    dtype={'zipcode': 'category',\n",
    "                           'waterfront': 'bool'})\n",
    "\n",
    "# We'll downsample in order to make plots a bit simpler and smaller to store\n",
    "# In particular Altair defaults to a limit of 5000 observations\n",
    "sales = sales.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the classic `iris` and `mtcars` datasets for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "cars = pd.read_csv('mtcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is the oldest and still the fundamental plotting library in Python. It has a huge range of capabilities. Many other libraries (including Seaborn) use Matplotlib as a back-end renderer.\n",
    "\n",
    "Today we're focussing on plotting tabular data. We won't touch on all Matplotlib's capabilities. If you want to see more of the range of things Matplotlib can do, you can look through the [Matplotlib gallery](https://matplotlib.org/gallery.html.), or try out this excellent [Matplotlib tutorial](https://www.labri.fr/perso/nrougier/teaching/matplotlib/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simple Matplotlib plots, inline in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[1,2,3],y=[5,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iris['petal_length'], iris['petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's better to use the object-oriented Axes methods to draw the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(iris['petal_length'], iris['petal_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example Matplotlib plot with legend and annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T05:36:41.975324Z",
     "start_time": "2018-01-14T05:36:41.805467Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "y = [2,5,10,17,26]\n",
    "y2 = [1,4,9,11,9]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, c='blue', label='Projected')\n",
    "ax.scatter(x, y2, c='red', label='Actual')\n",
    "fig.legend()\n",
    "ax.annotate(\"where it all went wrong\", \n",
    "                                 xy=(3,10), xytext=(1,12),\n",
    "                                 arrowprops={'width':2})\n",
    "\n",
    "fig.savefig('example_matplotilb.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn builds on Matplotlib. Some nice features are:\n",
    "\n",
    "- works directly with Pandas dataframes, concise syntax\n",
    "- lots of plot types, including some more advanced options\n",
    "- statistical plotting: many plots do summary statistics for you\n",
    "- good default aesthetics and easy control of aesthetics\n",
    "- uses Matplotlib, so can use all Matplotlib backends (incl lots of image file formats)\n",
    "- underlying Matplotlib objects can be tweaked directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, here's the plot we made before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Time': [1,2,3,4,5],\n",
    "    'Projected': [2,5,10,17,26],\n",
    "    'Actual': [1,4,9,11,9]\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(data=df, x='Time', y='Actual', color='red', ax=ax)\n",
    "sns.lineplot(data=df, x='Time', y='Projected', color='blue', ax=ax)\n",
    "\n",
    "ax.set_ylabel('Huge profits')\n",
    "\n",
    "ax.annotate(\"where it all went wrong\", \n",
    "                                 xy=(3,10), xytext=(1,12),\n",
    "                                 arrowprops={'width':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can add changes like annotations in exactly the same way, as we have Matplotlib Figure and Axes objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: seaborn scatterplot can do hue as just another channel\n",
    "sns.scatterplot(data=iris, \n",
    "                x='petal_length', \n",
    "                y='petal_width',\n",
    "                hue='species',\n",
    "                size='sepal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn and Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases we can use Seaborn by passing in lists (or arrays or series) directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:54.489607Z",
     "start_time": "2018-01-14T23:56:53.283680Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=['A','B','C'], y=[33,44,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However Seaborn is aware of Pandas and it is very common to use Seaborn directly with DataFrames. Plotting functions can take a DataFrame as their `data` parameter and then refer directly to column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:54.706924Z",
     "start_time": "2018-01-14T23:56:54.492344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=iris, x='species', y='petal_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Seaborn has interpreted the `x` and `y` arguments as field names in the supplied DataFrame. Notice also that Seaborn has performed the summary statistics for us - in this case, using the default `estimator`, which is `mean()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also what happens if we simply swap the `x` and `y` parameters. Seaborn will automatically deduce that the categorical or string-like variable must be the bar labels, and the numeric variable must be the numeric axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:54.706924Z",
     "start_time": "2018-01-14T23:56:54.492344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=iris, y='species', x='petal_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the grouping is not obviously categorical? How could we fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=cars, x='acceleration', y='origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter orient=\"h\", or appropriate Pandas dtype\n",
    "cars['origin'] = cars['origin'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: \n",
    "\n",
    "**1:** Create a count plot using `sns.countplot()` on the `ltee` data, showing how many clones have each `Mutator` phenotype. Note that you do not need to specify the `y` axis variable for a countplot, just the `x` axis variable (i.e. category).\n",
    "\n",
    "**2:** Create a (vertical) bar plot using the `sales` data, showing how house prices vary with the value of the property `grade`.\n",
    "\n",
    "Bar plots are often deplored as a way of showing statistical estimates, as only the top of the bar is really important, and the bar itself is a visual distraction. A point plot is an alternative, and plots like box plots can show more information. Several other plot types also show distributional information within categories.\n",
    "\n",
    "**3:** Reproduce the plot you just made, using instead each of the Seaborn functions:\n",
    "\n",
    "- pointplot()\n",
    "- boxplot()\n",
    "- violinplot()  (try the `scale` parameter)\n",
    "- boxenplot()\n",
    "- stripplot() [SEE WARNING]  (try the `jitter` parameter)\n",
    "- swarmplot() [SEE WARNING]\n",
    "\n",
    "Note what sort of information about the distribution is shown by each.\n",
    "\n",
    "WARNING: `stripplot()` and `swarmplot()` will plot individual data points. There are too many house sales to easily display in this way - you may want to subsample the dataframe with e.g.  `data=sales.sample(100)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=ltee, x='Mutator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=sales, x='grade', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?sns.violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=sales, x='grade', y='price', scale='width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many Seaborn plotting functions take a `hue` parameter. This colours the plot elements by some categorical variable, but more than this, summary statistics are calculated for each level of the hue variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=ltee, \n",
    "                x='Generation', \n",
    "                y='Synonymous Base Substitutions', \n",
    "                palette='bright', hue='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=ltee, \n",
    "            x='Generation', \n",
    "            y='Synonymous Base Substitutions', \n",
    "            palette='bright', hue='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=ltee, \n",
    "            x='Generation', \n",
    "            y='Relative fitness', \n",
    "            palette='bright', hue='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:09.975033Z",
     "start_time": "2018-01-15T00:00:09.367327Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=sales, x='sqft_living', y='price', hue='waterfront')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises:\n",
    "\n",
    "1. Subset the `ltee` dataset to get only the clones where the `Mutator` value is \"PM\"\n",
    "2. Create an `lmplot` of `Total Mutations` over time (i.e. against `Generation`). Do this without a `hue` parameter, then add in `Population` as the `hue` parameter. \n",
    "3. Try adding the `hue` parameter to one of your previous plots of some other type - for instance, a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ltee[ ltee['Mutator']==\"PM\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, convenient but less flexible\n",
    "subset = ltee.query('Mutator==\"PM\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=subset, x='Generation', y='Total Mutations', \n",
    "           hue='Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we'd wanted to colour scatter points by some continuous variable, `hue` can be made to work, but doesn't really make sense as it is intended for discrete values. In this specific case, we could pass our colour variable down to the underlying Matplotlib scatter call via the `scatter_kws` parameter. We'll look more at this later. Or, if we're not trying to fit a linear model, we could just use Seaborn aesthetics around a Matplot scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:10.985210Z",
     "start_time": "2018-01-15T00:00:09.978297Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = sales.sample(200)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(x=sales['long'], y=sales['lat'], c=sales['price'].apply(np.log), \n",
    "               alpha=0.5, s=7, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete color palettes, as needed by the `hue` parameter, Seaborn has a `color_palette()` function to generate a useful range of palettes. You can find [a tutorial on choosing color palettes here](https://seaborn.pydata.org/tutorial/color_palettes.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn has some plotting functions which create more complex figures made of multiple subplots. These include `cat()`, `catplot()`, `jointplot()`, `lmplot()` and `clustermap()`. Let's see a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:11.855411Z",
     "start_time": "2018-01-15T00:00:10.988170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jointplot shows a scatter or density plot, with marginal distributions\n",
    "sns.jointplot(data=sales, x='sqft_living', y='price') #, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:12.995121Z",
     "start_time": "2018-01-15T00:00:11.858767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pairplot shows pairwise relationships between variables\n",
    "sns.pairplot(data=ltee,\n",
    "             vars=['Generation', 'Total Mutations', 'Nonsynonymous Base Substitutions', 'IS Element Insertions'])\n",
    "             #hue='Mutator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:12.995121Z",
     "start_time": "2018-01-15T00:00:11.858767Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pairplot shows pairwise relationships between variables\n",
    "sns.pairplot(data=ltee,\n",
    "             vars=['Generation', \n",
    "                   'Total Mutations', \n",
    "                   'Nonsynonymous Base Substitutions', \n",
    "                   'IS Element Insertions'],\n",
    "             hue='Mutator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:13.461175Z",
     "start_time": "2018-01-15T00:00:12.998412Z"
    }
   },
   "outputs": [],
   "source": [
    "# catplot conditions different subplots on different categorical variable values\n",
    "# we map variables to row and column of a grid of plots (as well as to hue)\n",
    "# in this example, we just use columns, and so have only one row\n",
    "sns.catplot(data=cars, kind='box',\n",
    "               x='year', y='mpg', \n",
    "               row='origin',\n",
    "               aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs a single (unfaceted) boxplot\n",
    "sns.boxplot(data=cars, x='year', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Create a joint plot using the `ltee` data showing `Cell size` against `Relative fitness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=ltee,\n",
    "              x='Relative fitness',\n",
    "              y='Cell size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T11:39:43.169894Z",
     "start_time": "2018-01-11T11:39:43.013278Z"
    }
   },
   "source": [
    "#### Exercise: \n",
    "\n",
    "Design a plot using `sns.catplot()`, to show the relationship between house price and: grade, view, and whether the property is waterfront. Available channels of information are:\n",
    "\n",
    "- x and y coordinates\n",
    "- hue\n",
    "- row and column of subplot (`row` and `col`)\n",
    "\n",
    "You can set the `kind` parameter to the kind of plot you want to make: point, bar, count, box, violin, or stripplot.\n",
    "\n",
    "You do not have to use all of these channels - in fact your plot may be difficult to take in if you do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour and Palettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn has good colour options. There are a few ways we could want to use access colours:\n",
    "\n",
    "* Specify an individual colour for some plot element. Matplotlib named colours can be used, or rgb values specified. Also check out the `sns.xkcd_rgb` dictionary of 954 named colours from the XKCD colour survey - for instance, `sns.xkcd['fire engine red']` is a colour.\n",
    "* Specify a colormap, for mapping a continuous value to colour. All Matplotlib colormaps can be used by name. You can see these under the `plt.cm` module. Seaborn's `light_palette()` and `dark_palette()` functions can also generate custom colourmaps easily.\n",
    "* Specify a discrete colour palette (a list of colours), for mapping a discrete or categorical variable to colour. In Seaborn, there is a distinction between colour palettes and colormaps. In general, you can create a colour palette by explicitly listing some colours, or by selecting a series of colours along some colormap. There are several functions, including `color_palette()`, `light_palette()`, `dark_palette()`, `diverging_palette()` and `xkcd_palette()`, which can produce many discrete colour palettes of whatever size you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:08.929020Z",
     "start_time": "2018-01-15T00:00:08.834779Z"
    }
   },
   "outputs": [],
   "source": [
    "# An example discrete colour palette of 7 colours, based on the XKCD colour \"denim blue\"\n",
    "# palplot is a function to visualise a palette\n",
    "palette = sns.light_palette(\"denim blue\", n_colors=7, input='xkcd')\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:09.043908Z",
     "start_time": "2018-01-15T00:00:08.932500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Equivalently (to illustrate that we can use an rgb value directly)\n",
    "denim_blue = sns.xkcd_rgb[\"denim blue\"]\n",
    "print(denim_blue)\n",
    "palette = sns.light_palette(denim_blue, n_colors=7)\n",
    "print(palette)\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try out the Seaborn function `choose_diverging_palette()` in your notebook (it requires no arguments). You can assign the result to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.choose_diverging_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.xkcd_rgb['denim blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a heatmap. Unlike most Seaborn functions, heatmaps take data in wide form. We'll need to pivot our long-form data to get a table of numbers, indexed by two variables. The heatmap function will then transform each number to a colour via a continuous colourmap.\n",
    "\n",
    "#### Exercise: \n",
    "\n",
    "Use `ltee.pivot_table()` to produce a table showing the (average) number of mutations per Population and Generation. The x-axis (column headers) should be the values of the `Generation` variable, and the rows (index) should be the values of the `Population` variable. If you're new to pivot tables in Pandas, check the example below that uses the `cars` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_table = ltee.pivot_table(index='Population', \n",
    "                                   columns='Generation',\n",
    "                                   values='Total Mutations',\n",
    "                                   aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:09.103356Z",
     "start_time": "2018-01-15T00:00:09.048120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here's an example using the toy dataset\n",
    "# Avoid looking at the details first if you want to solve the above without hints!\n",
    "\n",
    "speed_table = cars.pivot_table(index='origin', columns='year', values='mpg', aggfunc=np.mean)\n",
    "speed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:09.363724Z",
     "start_time": "2018-01-15T00:00:09.106153Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(speed_table, vmin=0, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises:\n",
    "\n",
    "* If you haven't already, produce a heatmap with the `ltee` pivot table you produced above. You will probably want to leave off the annotations unless your plot is very large. \n",
    "* Specify a different colourmap using the `cmap` parameter to `heatmap`. An ascending (not diverging) colourmap is appropriate for counts that are all positive.\n",
    "* Some populations have far more mutations than others, and so our heatmap doesn't really show detail for the lower end of the scale. Try to plot a heatmap where colour is based on the *log* of the mutation count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:09.363724Z",
     "start_time": "2018-01-15T00:00:09.106153Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(np.log(mutations_table), vmin=0, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn and Matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn plotting functions call Matplotlib plotting functions, and we can pass arguments down to these underlying functions.\n",
    "\n",
    "For instance, `lmplot()` calls `scatter()` and `plot()` to draw points and lines. We can pass arguments down using `scatter_kws` and `line_kws`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:14.587879Z",
     "start_time": "2018-01-15T00:00:13.464146Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=sales, x='grade', y='price',\n",
    "           scatter_kws={'alpha': 0.3},\n",
    "           line_kws={'linestyle': 'dashed', 'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Which underlying plotting function is called by your `catplot` above? You can try passing arguments to it with catplot's `kwargs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the object returned by a Seaborn plot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:14.737395Z",
     "start_time": "2018-01-15T00:00:14.590597Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.countplot(ltee['Mutator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:14.745309Z",
     "start_time": "2018-01-15T00:00:14.740201Z"
    }
   },
   "outputs": [],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Matplotlib `Axes` object. We can use all the usual `Axes` methods to tweak the plot. What's more, if we have an existing `Axes` object, we can ask Seaborn to draw the plot onto it by passing it in as the `ax` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:14.909998Z",
     "start_time": "2018-01-15T00:00:14.748778Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, myaxes = plt.subplots(figsize=(7,5), facecolor=sns.xkcd_rgb['pale pink'])\n",
    "\n",
    "sns.countplot(ltee['Mutator'], color='purple', ax=myaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the plot is still attached to `fig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:14.995755Z",
     "start_time": "2018-01-15T00:00:14.912758Z"
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simpler Seaborn plotting functions return `Axes` objects, and can take an `Axes` as a parameter. More complex functions like `jointplot()` and `catplot()` need to make multiple subplots. What do they return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:16.110729Z",
     "start_time": "2018-01-15T00:00:14.998478Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(data=ltee,\n",
    "             vars=['Generation', 'Total Mutations', 'Nonsynonymous Base Substitutions', 'IS Element Insertions'],\n",
    "             hue='Mutator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:16.120201Z",
     "start_time": "2018-01-15T00:00:16.113887Z"
    }
   },
   "outputs": [],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:16.132657Z",
     "start_time": "2018-01-15T00:00:16.123808Z"
    }
   },
   "outputs": [],
   "source": [
    "type(g.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:16.145801Z",
     "start_time": "2018-01-15T00:00:16.135870Z"
    }
   },
   "outputs": [],
   "source": [
    "g.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:16.585296Z",
     "start_time": "2018-01-15T00:00:16.150407Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these more complex functions produce entire Matplotlib `Figure` objects, which can contain multiple `Axes`. The `Figure`, however, comes wrapped in a Seaborn class, which provides some convenient functions to manipulate the figure properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:00:18.201406Z",
     "start_time": "2018-01-15T00:00:16.588311Z"
    }
   },
   "outputs": [],
   "source": [
    "# g.set sets a property on all Axes in the Figure\n",
    "# set x-axis to log scale:\n",
    "g.set(xscale='log')\n",
    "g.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seaborn classes commonly returned are:\n",
    "\n",
    "- JointGrid : a central bivariate plot with two marginal univariate plots. Used by `jointplot()`. \n",
    "- PairGrid : a grid of subplots for plotting pairwise relationships. Has convenience functions for mapping plots onto diagonal and non-diagonal elements. Used by `pairplot()`.\n",
    "- FacetGrid : a grid of subplots showing the same relationship, conditioned on some variable across different subplots. Designed to map fields of a Pandas DataFrame to different rows, columns, and hues. Used by `catplot()` and `lmplot()`.\n",
    "\n",
    "It's possible to instantiate these classes yourself for custom plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy hints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Jupyter shortcut keys:\n",
    "\n",
    "- Esc : get into Command mode (leaves Edit mode)\n",
    "- Enter : edit a cell (puts you in Edit mode)\n",
    "- h : see help (see all commands)\n",
    "- Shift+Enter or Ctrl+Enter : run the code in the cell\n",
    "- a / b : add new cell above/below\n",
    "- m : turn current cell into a Markdown cell\n",
    "- y : turn current cell into a Code cell\n",
    "- 1-6 : turn current cell into a heading (a type of Markdown cell)\n",
    "\n",
    "You can get help on Python objects and functions with `help()` or the `?` operator.\n",
    "\n",
    "In general, we are using plotting libraries that return objects encapsulating the plot. You can check the type of these returned objects with `type()`. \n",
    "\n",
    "Some of the plotting libraries we use need to communicate a lot of data to the browser. Current versions of Jupyter shouldn't have a problem, but if you are running an older version, you may need to launch this notebook with a higher data rate limit: `jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altair is not bundled with Anaconda - you may need\n",
    "\n",
    "`conda install -c conda-forge altair vega`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:55:16.420432Z",
     "start_time": "2018-01-15T00:55:16.416622Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:55:16.929054Z",
     "start_time": "2018-01-15T00:55:16.903001Z"
    }
   },
   "outputs": [],
   "source": [
    "# We may want to use some colours etc from other libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and initialise altair\n",
    "import altair as alt\n",
    "# this line is needed in jupyter notebook, but not jupyter-lab\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop we're going to load in two main datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTEE data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from the [Long Term Evolution Experiment (LTEE)](http://myxo.css.msu.edu/ecoli/). This experiment has been running for over 30 years and over 50,000 E. coli generations, and is still ongoing. Twelve separate populations of E. coli have been propagated for the life of the experiment. Every 500 generations, each population is cloned and stored, allowing researchers to study evolutionary behaviour over the long term, and to \"rewind and replay\" alternate evolutionary trajectories by propagating from an earlier clone. \n",
    "\n",
    "Several interesting events have occurred during the experiment. Some populations have spontaneously developed hypermutator phenotypes. In addition, around generation 31,000 one population, Ara-3, spontaneously developed a rare and novel Cit+ mutation, giving it the ability to metabolise citrate in the substrate.\n",
    "\n",
    "There have been many publications from this experiment. A handful:\n",
    "\n",
    "- [Blount et al 2008: Historical contingency and the evolution of a key innovation in an experimental population of Escherichia coli](https://www.pnas.org/content/105/23/7899) - on the spontaneous development of citrate metabolisation and on potentiating mutations\n",
    "- [Tenaillon et al 2016: Tempo and mode of genome evolution in a 50,000-generation experiment](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4988878) - various investigations by sequencing and variant-calling over 50,000 generations of clones, including discussion of hypermutator phenotypes and genetic drift vs natural selection.\n",
    "\n",
    "Sequence data from clones is available, but for this workshop we'll just be using some published tabular data.\n",
    "\n",
    "A version of this dataset is also used by the [Data Carpentry lessons on Genomics](https://datacarpentry.org/genomics-workshop/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we'll use a large flat file containing both sample metadata on each clone, and information on observed mutations in their genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have done the pandas and data tidying workshop and saved the final file,\n",
    "# you can try reading that file in here if you prefer\n",
    "ltee = pd.read_csv('ltee_merged.csv',\n",
    "                   index_col = 'Strain ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House sales data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data represents house sales in Seattle in 2014 and 2015. We have information on the houses themselves: location, size, quality, view, and whether the house is tagged as 'waterfront' or not. We also have information on the date and price of each sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-14T23:56:53.195524Z",
     "start_time": "2018-01-14T23:56:53.140978Z"
    }
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"housing-data-10000.csv\", \n",
    "                    usecols=['id','date','price','lat','long', 'zipcode',\n",
    "                             'waterfront','view','grade','sqft_living'],\n",
    "                    parse_dates=['date'], \n",
    "                    dtype={'zipcode': 'category',\n",
    "                           'waterfront': 'bool'})\n",
    "\n",
    "# We'll downsample in order to make plots a bit simpler and smaller to store\n",
    "# In particular Altair defaults to a limit of 5000 observations\n",
    "sales = sales.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the classic `iris` and `mtcars` datasets for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "cars = pd.read_csv('mtcars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Altair](https://altair-viz.github.io) is a library for creating interactive plots. \n",
    "\n",
    "Altair is built around the [Vega-Lite](https://vega.github.io/vega-lite/) schema, a \"visualisation grammar\". Altair plots are specified in Python, then converted behind the scenes to a declarative JSON structure that follows the Vega-Lite schema, which can then be rendered by a Javascript library.\n",
    "\n",
    "Altair works very well with Pandas - in fact, it usually expects data to be in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple interactive plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example of an Altair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Time': [1,2,3,4,5],\n",
    "    'Projected': [2,5,10,17,26],\n",
    "    'Actual': [1,4,9,11,9]\n",
    "})\n",
    "\n",
    "chart = alt.Chart(df)\n",
    "\n",
    "chart = chart.mark_line(color='blue')\n",
    "\n",
    "chart = chart.encode(x='Time', y='Projected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `mark_line()` tells Altair we want to draw a line, and `encode()` is used to assign our variables (columns of the DataFrame) to possible encoding channels of the line. We've just used `x` and `y`. Notice that we set the colour in `mark_line()`; if we'd wanted to set the colour to encode some variable, we would have set it in `encode()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple pan-and-zoom interactivity can be added with `.interactive()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(df)\n",
    "\n",
    "chart.mark_line(color='blue').encode(x='Time', y='Projected').interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to produce the chart we produced earlier, with scatter points, we can use `alt.layer()`, which takes the components as arguments, or just the `+` operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T00:55:27.518001Z",
     "start_time": "2018-01-15T00:55:27.491207Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Time': [1,2,3,4,5],\n",
    "    'Projected': [2,5,10,17,26],\n",
    "    'Actual': [1,4,9,11,9],\n",
    "})\n",
    "\n",
    "chart = alt.Chart(df)\n",
    "line = chart.mark_line(color='blue').encode(x='Time', y='Projected')\n",
    "points = chart.mark_point(color='red').encode(x='Time',y='Actual')\n",
    "\n",
    "# or alt.layer(line, points).interactive()\n",
    "(line + points).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Recreate, in Altair, the scatter plot of house sales with x-coordinates given by `longitude` and y-coordinates given by `latitude`. You can use `.mark_point()` or `.mark_circle()`. One issue you will discover, if you use the `x` and `y` encodings, is that Altair and Vega-lite include the axis zero by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "alt.Chart(data=sales)\\\n",
    "    .mark_circle(size=20)\\\n",
    "    .encode(alt.X('long', \n",
    "                  scale=alt.Scale(zero=False)), \n",
    "            alt.Y('lat', \n",
    "                  scale=alt.Scale(zero=False))) # or e.g. alt.Scale(domain=(45,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "alt.Chart(data=sales)\\\n",
    "    .mark_circle(size=20)\\\n",
    "    .encode(longitude='long',\n",
    "            latitude='lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altair recognises four fundamental [data types](https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types):\n",
    "\n",
    "| Data Type | Shorthand Code | Description |\n",
    "|-|-|-|\n",
    "| quantitative | Q | a continuous real-valued quantity |\n",
    "| ordinal | O | a discrete ordered quantity |\n",
    "| nominal | N | a discrete unordered category |\n",
    "| temporal | T | a time or date value |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales.sample(10))\\\n",
    "    .mark_bar()\\\n",
    "    .encode(x='date:N', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales.sample(10))\\\n",
    "    .mark_bar()\\\n",
    "    .encode(x='date:T', y='price:Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ltee['Read Length'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of sequencing experiments have been done on the LTEE data?\n",
    "\n",
    "chart = alt.Chart(data=ltee)\n",
    "\n",
    "chart.mark_point()\\\n",
    "    .encode(x=alt.X('Sequencing Depth', \n",
    "                    scale=alt.Scale(type='log')),\n",
    "            y='Read Type',\n",
    "            color='Read Length:N')  # try N, O, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of sequencing experiments have been done on the LTEE data?\n",
    "\n",
    "chart = alt.Chart(data=ltee)\n",
    "\n",
    "chart.mark_point()\\\n",
    "    .encode(x=alt.X('Sequencing Depth', \n",
    "                    scale=alt.Scale(type='log')),\n",
    "            y='Read Type',\n",
    "            color='Read Length:O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "* Colour your \"geographical\" scatter plot of house sales according to whether the property is or is not a waterfront property. What is the appropriate data type?\n",
    "* Colour according to price (if you prefer, try a log scale). What is the appropriate data type?\n",
    "* Colour according to view. What is the appropriate data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales)\\\n",
    "    .mark_circle(size=10)\\\n",
    "    .encode(y=alt.Y('lat', \n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            x=alt.X('long',\n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            color='waterfront:N',\n",
    "            tooltip='price')\\\n",
    "    .interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales)\\\n",
    "    .mark_circle(size=10)\\\n",
    "    .encode(y=alt.Y('lat', \n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            x=alt.X('long',\n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            color=alt.Color('price:Q', \n",
    "                            scale=alt.Scale(type='log')),\n",
    "            tooltip='price')\\\n",
    "    .interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales)\\\n",
    "    .mark_circle(size=10)\\\n",
    "    .encode(y=alt.Y('lat', \n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            x=alt.X('long',\n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            color='view:O',\n",
    "            tooltip='price')\\\n",
    "    .interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks and encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altair has various marks used to draw different kinds of plots. For instance:\n",
    "\n",
    "* `mark_point()` : points on a scatter plot\n",
    "* `mark_bar()` : rectangular bars, in e.g. a bar plot or histogram\n",
    "* `mark_area()` : filled/shaded areas\n",
    "\n",
    "The full list of marks can be found at [https://altair-viz.github.io/user_guide/marks.html](https://altair-viz.github.io/user_guide/marks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign variables of the DataFrame to different encoding channels. For instance:\n",
    "\n",
    "* `x` and `y` : position of mark (scatterpoint position, top of bar-chart bar, etc)\n",
    "* `color` : colour of the mark (colour of point, bar, shaded area etc)\n",
    "* `size` : size of the mark (point size, bar width, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a list of encodings at [https://altair-viz.github.io/user_guide/encoding.html](https://altair-viz.github.io/user_guide/encoding.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: marks from common base\n",
    "base = alt.Chart(sales.sample(10))\\\n",
    "    .encode(x='date:T', y='price:Q') \n",
    "\n",
    "base.mark_point(color='red') | base.mark_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot demo\n",
    "base = alt.Chart(ltee)\n",
    "\n",
    "base.mark_boxplot().encode(x='Population', \n",
    "                           y=alt.Y('Total Mutations', scale=alt.Scale(type='log')))\n",
    "# Log scale works here\n",
    "# Color also works here (sort of!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(ltee)\n",
    "\n",
    "base.mark_boxplot()\\\n",
    "    .encode(x='Population:N', \n",
    "            y=alt.Y('Total Mutations',\n",
    "                  scale=alt.Scale(type='log')),\n",
    "            color='Mutator')\n",
    "# Note that some info is hidden with colour - not a true grouped boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ltee['Mutator'], ltee['Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(ltee)\\\n",
    "    .mark_line()\\\n",
    "    .encode(x=alt.X('Generation', scale=alt.Scale(domain=[0,10000])),\n",
    "            y=alt.Y('Relative fitness', scale=alt.Scale(zero=False)),\n",
    "            color='Population')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many common plot types involve summarising the data:\n",
    "\n",
    "* histograms involve putting some continuous variable into bins (_binning_), and then _counting_ how many samples are in each bin\n",
    "* bar charts or point plots usually involve plotting the _mean_ of some variable, and possibly error bars based on _confidence intervals_\n",
    "* box plots usually involve finding the _mean_, _quartiles_, _min_ and _max_ of some variable (although as of v3 Altair has a built-in boxplot mark type).\n",
    "\n",
    "Combining aggregation functions with different kind of marks is very powerful. \n",
    "\n",
    "Most aggregations have a shorthand string form (e.g. encode `y='count()'`) and a longer form (e.g encode `y=alt.Y(aggregate='count', type='quantitative')`).\n",
    "\n",
    "Binning is done using an explicit axis object like `alt.X()` or `alt.Y()`, with `bin=True` or `bin=alt.Bin()`.\n",
    "\n",
    "You can find a list of aggregation functions at [https://altair-viz.github.io/user_guide/encoding.html#binning-and-aggregation](https://altair-viz.github.io/user_guide/encoding.html#binning-and-aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(iris)\\\n",
    "    .mark_bar()\\\n",
    "    .encode(x='species',\n",
    "            y='mean(petal_length)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Demo: Histogram of iris petal lengths\n",
    "alt.Chart(iris)\\\n",
    "    .mark_bar()\\\n",
    "    .encode(x=alt.X('petal_length', bin=alt.Bin(step=0.5)),\n",
    "            y='count()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: LTEE heatmap\n",
    "chart = alt.Chart(ltee)\n",
    "chart = chart.mark_rect()\\\n",
    "    .encode(x='Generation:O', \n",
    "            y='Population', \n",
    "            color=alt.Color('mean(Total Mutations)',\n",
    "                            scale=alt.Scale(type='log')))\n",
    "\n",
    "# saving the chart as html\n",
    "chart.interactive().save('ltee_heatmap.html')\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Using `mark_bar()`, create a histogram of total mutation counts from the `ltee` data.\n",
    "2. Try the same plot but using `.mark_area()`.\n",
    "3. On the original histogram, try setting the `color` encoding to the `Mutator` field. Do you get a stacked or layered histogram by default? (This can be controlled using the `stack` parameter to `alt.Y()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = alt.Chart(ltee)\n",
    "\n",
    "chart.mark_bar()\\\n",
    "    .encode(alt.X('Total Mutations', \n",
    "                  bin=alt.Bin(maxbins=20)),\n",
    "            y=alt.Y('count()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = alt.Chart(ltee)\n",
    "\n",
    "chart.mark_area()\\\n",
    "    .encode(alt.X('Total Mutations', \n",
    "                  bin=alt.Bin(maxbins=20)),\n",
    "            y=alt.Y('count()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = alt.Chart(ltee)\n",
    "\n",
    "chart.mark_bar(opacity=0.5)\\\n",
    "    .encode(alt.X('Total Mutations', \n",
    "                  bin=alt.Bin(maxbins=20)),\n",
    "            y=alt.Y('count()', stack=None),\n",
    "            color='Mutator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactivity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hover text can be added to a plot simply by setting the `tooltip` encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "On your scatter plot of house location, set the hover info to display the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sales)\\\n",
    "    .mark_circle(size=10)\\\n",
    "    .encode(y=alt.Y('lat', \n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            x=alt.X('long',\n",
    "                    scale=alt.Scale(zero=False)),\n",
    "            tooltip='price')\\\n",
    "    .interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic pan-and-zoom interactivity is set with `.interactive()`. This is actually short for:\n",
    "\n",
    "```\n",
    "chart.add_selection(\n",
    "    alt.selection_interval(bind='scales')\n",
    ")\n",
    "```\n",
    "\n",
    "This means we've added a behaviour where dragging the mouse (selecting an interval) causes the plot to zoom and pan (bind='scales'). We can create custom interactive behaviour with [bindings, selections, and conditions](https://altair-viz.github.io/user_guide/interactions.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define particular kinds of selections with Altair functions:\n",
    "\n",
    "* `selection_interval()` allows us to select everything in a region of the plot by dragging over it\n",
    "* `selection_single()` allows us to select a single element by clicking on it\n",
    "* `selection_multi()` allows us to select multiple elements by holding shift and clicking\n",
    "\n",
    "`add_selection()` is used to the defined selection object to a plot.\n",
    "\n",
    "`alt.condition()` is used to change plot encodings conditional on whether an element is currently selected or not. This is what makes the plots interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "You're given the below plot, where we've added a selection that changes the colour of the points in `area_price_chart` when selected. Edit the `location_chart` so that when points are selected in `area_price_chart`, they are _also_ highlighted in `location_chart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T19:10:31.343996Z",
     "start_time": "2018-07-16T19:10:30.056261Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_houses = alt.selection_interval()\n",
    "\n",
    "area_price_chart = alt.Chart(data=sales)\\\n",
    "    .mark_circle(size=20, opacity=0.5)\\\n",
    "    .encode(\n",
    "        x='sqft_living:Q',\n",
    "        y=alt.Y('price:Q', scale=alt.Scale(type='log')),\n",
    "        color=alt.condition(selected_houses,\n",
    "                            alt.value('red'),\n",
    "                            alt.value('lightgrey')))\\\n",
    "    .add_selection(selected_houses)\n",
    "\n",
    "# We could optionally .add_selection to the second chart too\n",
    "# This would mean points could be selected using either chart\n",
    "location_chart = alt.Chart(data=sales)\\\n",
    "    .mark_circle(size=20)\\\n",
    "    .encode(\n",
    "        alt.X('long', scale=alt.Scale(zero=False)),\n",
    "        alt.Y('lat', scale=alt.Scale(zero=False)),\n",
    "        color=alt.condition(selected_houses,\n",
    "                            alt.value('red'),\n",
    "                            alt.value('lightgrey'))\n",
    "        )\n",
    "\n",
    "area_price_chart | location_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just colour-on-select example\n",
    "\n",
    "# Note we need ltee.reset_index()\n",
    "# Altair needs 'Strain ID' to be a column, not the index, to use it\n",
    "# Also note selected points are coloured by a variable - Altair's default assumption\n",
    "\n",
    "selected = alt.selection_interval()\n",
    "\n",
    "chart = alt.Chart(ltee.reset_index())\\\n",
    "    .mark_circle()\\\n",
    "    .encode(x='Generation',\n",
    "            y='Total Mutations',\n",
    "            color=alt.condition(selected,\n",
    "                                'Population',\n",
    "                                alt.value('gray')),\n",
    "            tooltip='Strain ID')\\\n",
    "    .add_selection(selected)\n",
    "\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
